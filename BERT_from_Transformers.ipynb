{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT from Transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGsewO3xCs8eOwjOqBD5kF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb4d32313a5a480595e689167285e71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_91c56308b16a45ccad4844db906163cf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc471f3fe1514f8a8998f1b95b2bf8d0",
              "IPY_MODEL_462ba81e1dd943aba0ed83234c1b6178"
            ]
          }
        },
        "91c56308b16a45ccad4844db906163cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc471f3fe1514f8a8998f1b95b2bf8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f59a756cbfd24ae2bcfb827cc965be39",
            "_dom_classes": [],
            "description": "Iteration",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1563,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1563,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e015715bf2c4fc7b5fe77daa17999b3"
          }
        },
        "462ba81e1dd943aba0ed83234c1b6178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_991c72cac18a4110a02a313e79468e68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1563/1563 [13:02&lt;00:00,  2.30it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31107c8007cd4e7fb74ec2bc7c1156db"
          }
        },
        "f59a756cbfd24ae2bcfb827cc965be39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e015715bf2c4fc7b5fe77daa17999b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "991c72cac18a4110a02a313e79468e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31107c8007cd4e7fb74ec2bc7c1156db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShwetaBaranwal/BERT/blob/master/BERT_from_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAcDYH8yqNpT",
        "colab_type": "code",
        "outputId": "4e5bf7ac-0df6-4429-e7dd-144bdc494c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\r\u001b[K     |▊                               | 10kB 29.0MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 5.4MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 5.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 7.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 10.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 225kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 235kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 245kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 256kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 266kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 276kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 286kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 296kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 307kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 317kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 327kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 337kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 348kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 358kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 368kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 378kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 389kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 399kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 409kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 419kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 430kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 440kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 450kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 460kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 471kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 35.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 39.0MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 45.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 49.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 51.5MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 54.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 54.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 53.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 55.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 56.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 56.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 56.8MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 56.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 56.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 56.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 56.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 56.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 56.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 56.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 38kB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 48.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=5671cfd14a9a1ddb6b2a7dbc26f881ca1815ae1174079a9b4dfe57fa12b23e16\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxqJhJTaB6Ib",
        "colab_type": "code",
        "outputId": "60724507-152e-4b01-e223-0bb4d12ae92c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import transformers\n",
        "from transformers import glue_compute_metrics as compute_metrics\n",
        "from transformers.optimization import AdamW\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import trange, tqdm_notebook\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twY23S0xhxix",
        "colab_type": "text"
      },
      "source": [
        "Bert Tokenization:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chvOPghgvcLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "sent = 'This is my dog. His name is Jack.'\n",
        "sent2 = 'He loves playing.'\n",
        "inputs = tokenizer.encode_plus(text = sent, text_pair = sent2, add_special_tokens=True, max_length= 13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgPnTR27vcHg",
        "colab_type": "code",
        "outputId": "a625c883-704e-4163-8693-cf9572438644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "inputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'input_ids': [101,\n",
              "  2023,\n",
              "  2003,\n",
              "  2026,\n",
              "  3899,\n",
              "  1012,\n",
              "  2010,\n",
              "  102,\n",
              "  2002,\n",
              "  7459,\n",
              "  2652,\n",
              "  1012,\n",
              "  102],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro2S38j7vcEU",
        "colab_type": "code",
        "outputId": "a54bc9e2-b846-4320-931e-9806b6483388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer.decode([101,\n",
        "  2023,\n",
        "  2003,\n",
        "  2026,\n",
        "  3899,\n",
        "  1012,\n",
        "  2010,\n",
        "  2171,\n",
        "  2003,\n",
        "  102,\n",
        "  2002,\n",
        "  7459,\n",
        "  2652,\n",
        "  1012,\n",
        "  102])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] this is my dog. his name is [SEP] he loves playing. [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0KtEWFgh1Mo",
        "colab_type": "text"
      },
      "source": [
        "Model class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKXl_iv5oBOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTBASECLASSIFIER(nn.Module):\n",
        "  def __init__(self, bert_type, num_labels):\n",
        "    super(BERTBASECLASSIFIER, self).__init__()\n",
        "    self.bert_type = bert_type\n",
        "    self.num_labels = num_labels\n",
        "    self.bert = transformers.BertForSequenceClassification.from_pretrained(\n",
        "                      self.bert_type, \n",
        "                      num_labels=self.num_labels)\n",
        "\n",
        "  def forward(self, ids, mask_ids, token_ids, label):\n",
        "    _, logits = self.bert(\n",
        "                      input_ids = ids, \n",
        "                      attention_mask = mask_ids, \n",
        "                      token_type_ids = token_ids,\n",
        "                      labels = label)\n",
        "    return logits\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XHaCW7Xh4Tu",
        "colab_type": "text"
      },
      "source": [
        "Dataset class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-YvsoPywzC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertDatasetModule(Dataset):\n",
        "  def __init__(self, tokenizer, input_sent, max_length, target):\n",
        "    self.input_seq = input_sent\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "    self.target = target \n",
        "  \n",
        "  def __len__(self):\n",
        "        return len(self.input_seq)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    input_ = self.input_seq[idx]\n",
        "    inputs = self.tokenizer.encode_plus(text = input_, add_special_tokens=True, max_length= self.max_length)\n",
        "    ids = inputs['input_ids']\n",
        "    mask_ids = inputs['attention_mask']\n",
        "    token_ids = inputs['token_type_ids']\n",
        "\n",
        "    padding_len = self.max_length - len(ids)\n",
        "    ids = ids + ([0]*padding_len)\n",
        "    mask_ids = mask_ids + ([0]*padding_len)\n",
        "    token_ids = token_ids  + ([0]*padding_len)\n",
        " \n",
        "    return {'ids': torch.tensor(ids, dtype = torch.long),\n",
        "            'mask': torch.tensor(mask_ids, dtype = torch.long),\n",
        "            'token_type_ids': torch.tensor(token_ids, dtype = torch.long),\n",
        "            'target':  torch.tensor(self.target[idx], dtype = torch.int16)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6bv0qqakahJ",
        "colab_type": "text"
      },
      "source": [
        "Defining loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiO-AdwJ1niC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_func(outputs, targets):\n",
        "  return nn.CrossEntropyLoss()(outputs, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NwQF-Tvl0By",
        "colab_type": "text"
      },
      "source": [
        "Model training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC1WGutKmxem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_loop(dataloader, model, optimizer, device, max_grad_norm, scheduler=None):\n",
        "  model.train()\n",
        "  for bi, d in enumerate(tqdm_notebook(dataloader, desc=\"Iteration\")):\n",
        "    ids = d['ids']\n",
        "    mask_ids = d['mask']\n",
        "    token_ids = d['token_type_ids']\n",
        "    target = d['target']\n",
        "\n",
        "    ids = ids.to(device, dtype = torch.long)\n",
        "    mask_ids = mask_ids.to(device, dtype = torch.long)\n",
        "    token_ids = token_ids.to(device, dtype = torch.long)\n",
        "    target = target.to(device, dtype = torch.long)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(ids, mask_ids, token_ids, target)\n",
        "    loss = loss_func(output, target)\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if scheduler is not None:\n",
        "      scheduler.step()\n",
        "    if bi%100==0:\n",
        "      print (f\"bi: {bi}, loss: {loss}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD0yxvHSl_7K",
        "colab_type": "text"
      },
      "source": [
        "Model evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-ZMrZLqrZfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_loop(dataloader, model, device):\n",
        "  model.eval()\n",
        "  preds = None\n",
        "  out_label_ids = None\n",
        "  eval_loss = 0.0\n",
        "  eval_steps = 0\n",
        "\n",
        "  for bi, d in enumerate(dataloader):\n",
        "    ids = d['ids']\n",
        "    mask_ids = d['mask']\n",
        "    token_ids = d['token_type_ids']\n",
        "    target = d['target']\n",
        "\n",
        "    ids = ids.to(device, dtype = torch.long)\n",
        "    mask_ids = mask_ids.to(device, dtype = torch.long)\n",
        "    token_ids = token_ids.to(device, dtype = torch.long)\n",
        "    target = target.to(device, dtype = torch.long)\n",
        "    with torch.no_grad():\n",
        "      output = model(ids, mask_ids, token_ids, target)\n",
        "      loss = loss_func(output, target)\n",
        "      eval_loss += loss.mean().item()\n",
        "    \n",
        "    eval_steps += 1\n",
        "    if preds is None:\n",
        "      preds = output.detach().cpu().numpy()\n",
        "      out_label_ids = target.detach().cpu().numpy()\n",
        "    else:\n",
        "      preds = np.append(preds, output.detach().cpu().numpy(), axis=0)\n",
        "      out_label_ids = np.append(out_label_ids, target.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "  eval_loss = eval_loss/eval_steps\n",
        "  preds = np.argmax(preds, axis=1)\n",
        "  \n",
        "  conf_matrix = confusion_matrix(out_label_ids, preds)\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(conf_matrix)\n",
        "\n",
        "  tn, fp, fn, tp = conf_matrix.ravel()\n",
        "  print(f'tn:{tn}, fp:{fp}, fn:{fn}, tp:{tp}')\n",
        "\n",
        "  return eval_loss\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-C-WbenuWI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run():\n",
        "  MAX_SEQ_LENGTH = 128\n",
        "  TRAIN_BATCH_SIZE = 32\n",
        "  EVAL_BATCH_SIZE = 32\n",
        "  LEARNING_RATE = 1e-5\n",
        "  NUM_TRAIN_EPOCHS = 1\n",
        "  NUM_LABELS = 2\n",
        "  BERT_TYPE = \"bert-base-uncased\"\n",
        "  max_grad_norm = 1.0\n",
        "\n",
        "  train_df = pd.read_csv('train.csv', header=None)\n",
        "  test_df = pd.read_csv('test.csv', header=None)\n",
        "  train_df[0] = (train_df[0] == 2).astype(int)\n",
        "  test_df[0] = (test_df[0] == 2).astype(int)\n",
        "\n",
        "  tokenizer = transformers.BertTokenizer.from_pretrained(BERT_TYPE)\n",
        "  train_dataset = BertDatasetModule(\n",
        "      tokenizer = tokenizer,\n",
        "      input_sent = train_df[1],\n",
        "      max_length = MAX_SEQ_LENGTH,\n",
        "      target = train_df[0]\n",
        "  )\n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, shuffle=True)\n",
        "\n",
        "  eval_dataset = BertDatasetModule(\n",
        "      tokenizer = tokenizer,\n",
        "      input_sent = test_df[1],\n",
        "      max_length = MAX_SEQ_LENGTH,\n",
        "      target = test_df[0]\n",
        "  ) \n",
        "\n",
        "  eval_dataloader = DataLoader(eval_dataset, batch_size = EVAL_BATCH_SIZE, shuffle=False)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  model = BERTBASECLASSIFIER(BERT_TYPE, NUM_LABELS).to(device)\n",
        "\n",
        "  optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, correct_bias=False)\n",
        "\n",
        "  NUM_TRAIN_STEPS = int(len(train_dataset)/TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS) \n",
        "  scheduler = transformers.get_constant_schedule_with_warmup(\n",
        "                  optimizer, \n",
        "                  num_warmup_steps=100,\n",
        "                  # num_training_steps=NUM_TRAIN_STEPS,\n",
        "                  last_epoch=-1)\n",
        "  \n",
        "  for epoch in trange(NUM_TRAIN_EPOCHS):\n",
        "    train_loop(train_dataloader, model, optimizer, device, max_grad_norm, scheduler)\n",
        "  \n",
        "  res = eval_loop(eval_dataloader, model, device)\n",
        "  print(res)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUIgLbj79JQ1",
        "colab_type": "code",
        "outputId": "e329b19d-79cc-4e28-b1a2-776548ff7911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464,
          "referenced_widgets": [
            "bb4d32313a5a480595e689167285e71d",
            "91c56308b16a45ccad4844db906163cf",
            "dc471f3fe1514f8a8998f1b95b2bf8d0",
            "462ba81e1dd943aba0ed83234c1b6178",
            "f59a756cbfd24ae2bcfb827cc965be39",
            "7e015715bf2c4fc7b5fe77daa17999b3",
            "991c72cac18a4110a02a313e79468e68",
            "31107c8007cd4e7fb74ec2bc7c1156db"
          ]
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb4d32313a5a480595e689167285e71d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Iteration', max=1563, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "bi: 0, loss: 0.7080798149108887\n",
            "bi: 100, loss: 0.28074008226394653\n",
            "bi: 200, loss: 0.28822004795074463\n",
            "bi: 300, loss: 0.18763060867786407\n",
            "bi: 400, loss: 0.09493388235569\n",
            "bi: 500, loss: 0.1315157264471054\n",
            "bi: 600, loss: 0.08008087426424026\n",
            "bi: 700, loss: 0.2690439820289612\n",
            "bi: 800, loss: 0.14099784195423126\n",
            "bi: 900, loss: 0.08106669783592224\n",
            "bi: 1000, loss: 0.15364021062850952\n",
            "bi: 1100, loss: 0.18442435562610626\n",
            "bi: 1200, loss: 0.12855897843837738\n",
            "bi: 1300, loss: 0.1893499493598938\n",
            "bi: 1400, loss: 0.08701696991920471\n",
            "bi: 1500, loss: 0.06866840273141861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [13:02<00:00, 782.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[18027   973]\n",
            " [ 1380 17620]]\n",
            "tn:18027, fp:973, fn:1380, tp:17620\n",
            "0.15679249985720523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzPOTb9d0AEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}